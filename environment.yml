name: unified_vision_processor
channels:
  - conda-forge
  - defaults
variables:
  KMP_DUPLICATE_LIB_OK: "TRUE"
dependencies:
  - python=3.11
  - numpy
  - pandas
  - pillow
  - matplotlib
  - tqdm
  - pyyaml
  - scikit-learn
  - pip
  - ipykernel  # Required for Jupyter notebook support
  - ipywidgets  # Required for tqdm progress bars in Jupyter
  - pip:
    # Core dependencies for vision processing
    - transformers==4.45.2  # Fixed version for Llama-3.2-Vision compatibility
    - typer>=0.9.0
    - rich>=13.0.0
    - torch>=2.0.0
    - torchvision
    - accelerate  # Required for MPS/device mapping support
    - bitsandbytes  # Required for 8-bit quantization on V100 16GB
    - sentencepiece  # Required for tokenizer
    - protobuf  # Required for model loading
    - python-dotenv  # Required for .env file loading

# =====================================================
# ENVIRONMENT SETUP INSTRUCTIONS
# =====================================================
#
# Step 1: Create the conda environment
# ------------------------------------
# conda env create -f environment.yml
#
# Step 2: Activate the environment
# --------------------------------
# conda activate unified_vision_processor
#
# Step 3: Install PyTorch with CUDA support
# -----------------------------------------
# For V100 production (CUDA 11.x):
# conda install pytorch==2.0.1 torchvision==0.15.2 pytorch-cuda=11.8 -c pytorch -c nvidia
#
# For H200 development (CUDA 12.x):
# conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia
#
# Step 4: Register the environment as a Jupyter kernel
# ---------------------------------------------------
# python -m ipykernel install --user --name unified_vision_processor --display-name "Python (unified_vision_processor)"
#
# Step 5: Install package in development mode
# -------------------------------------------
# pip install -e .
#
# Step 6: Verify the installation
# -------------------------------
# python -c "import torch; print(f'PyTorch: {torch.__version__}')"
# python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
# python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
# python -c "import bitsandbytes; print('BitsAndBytes: OK')"
#
# =====================================================
# TROUBLESHOOTING
# =====================================================
#
# If conda activate fails in JupyterHub:
# --------------------------------------
# source /opt/conda/etc/profile.d/conda.sh && conda activate unified_vision_processor
#
# To list available kernels:
# -------------------------
# jupyter kernelspec list
#
# =====================================================
# NOTES
# =====================================================
# - transformers is pinned to 4.45.2 for Llama-3.2-Vision compatibility
# - bitsandbytes is required for 8-bit quantization on V100 16GB
# - ipykernel is included for Jupyter notebook support
# - KMP_DUPLICATE_LIB_OK=TRUE fixes OpenMP library conflicts
# - Designed for Mac M1 → 2x H200 → single V100 deployment pipeline